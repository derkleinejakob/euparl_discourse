\subsubsection{Semantic Embeddings}
Semantic embeddings have been widely used in political text analysis \citep{Miok2024, Nanni2021, Rudkowsky2018}. To capture  how different political groups address migration, we select candidate embedding models from the MTEB leaderboard \citep{enevoldsen2025mmtebmassivemultilingualtext}, based on overall performance and parameter count. Final selection is based on (i) intra- and interparty cosine similarities, (ii) logistic regression accuracy for party affiliation, and (iii) K-means clustering quality measured by homogenity and completeness. 
Based on these criteria, we choose google/embeddinggemma-300m \citep{embedding_gemma_2025} as our final embedding model, which is used for all subsequent embedding-based analysis. 

Because general-purpose semantic embeddings may be primarly capturing stylistic and topical variations, we test whether ideological difference is meaningfully encoded. For each candidate model, we compare intra- and interparty similarity distributions using two-sample Kolmogorov-Smirnov test with
Bonferroni correction ($\alpha = 0.05$, $\alpha\mbox{*} = 0.05 / m$). All models show significant distributional differences, with test statistic $\mathcal{D}$ ranging between 0.058 and 0.1.

Dimensionality reduction has been used to ascertain parties ideological shift over time and to reveal underlying political dimension with word associations for each reduced axis  \citep{Rheault2020-mr}. Exploratory analysis showed that, although party influence is present, it is not the defining factor of our semantic embeddings. To better understand how party affiliations manifest in the vector space, we aim to identify a subspace of the embedding space in which political and ideological differences become more salient.
To this end, we employ Partial Least Squares (PLS). PLS allows us to find directions in the embedding space that are maximally associated with party labels, making it suitable for uncovering latent political dimensions that are not necessarily dominant in the overall variance of the data. To mitigate and quantify temporal bias in our PLS analysis, we excluded written speeches predominantly occurring in 2015 and 2016 and fitted the PLS model on the remaining 5,433 observations. Furthermore, we employed a leave-one-out cross-validation strategy adapted for temporal data \citep{https://doi.org/10.1111/ecog.02881}

The prevalence of established migration-related rhetoric was assessed using semantic search in a shared embedding space. We used 30 migration narratives identified in a recent report by the European Commission’s Joint Research Centre \citep[p.130]{seiger_navigating_2025}, organized into four broader ``supernarratives.'' Each narrative was represented by a short descriptive sentence and embedded using the model’s built-in ``retrieval-query'' prompt.

Semantic proximity between narratives and speeches was quantified using cosine similarity. Similarity scores were averaged across narratives within each supernarrative to capture high-level trends. To control for keyword-driven effects, we additionally constructed a control narrative at the presumbaly opposite end of the rhetorical spectrum (``We need to respect humanitarian principles in handling migration'').

To validate that narrative similarity captured meaningful political differences, we correlated similarity scores with expert-coded party positions on migration policy and overall ideology \citep{rovny_CHES_2024}. Pearson correlations were evaluated using Bonferroni-adjusted significance thresholds. Temporal trends and party-block differences in narrative prevalence were analysed using linear mixed-effects models with random intercepts and slopes at the party-block level. Because separate models were estimated for each of the five supernarratives plus the control, significance levels were Bonferroni-corrected to $p = 0.05/6$.