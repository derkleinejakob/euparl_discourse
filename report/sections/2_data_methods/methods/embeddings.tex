\subsubsection{Semantic Embeddings}
% Semantic embeddings have been widely used in political text analysis \citep{Miok2024, Nanni2021}. %, Rudkowsky2018}. 
A pool of candidate embedding models was selected from the MTEB leaderboard \citep{enevoldsen2025mmtebmassivemultilingualtext} based on overall performance and parameter count. 
% Note: I reordered this because it to me makes more sense to first say, all models showed significant effects; then we chose
Because general-purpose semantic embeddings may primarily capture stylistic and topical variations, we tested whether ideological difference is meaningfully encoded in the embeddings. For each candidate model, we compared intra- and interparty similarity distributions using a two-sample Kolmogorov-Smirnov test with Bonferroni correction. All models show significant distributional differences.%, with the test statistic $\mathcal{D}$ ranging between 0.058 and 0.1.

To best capture political orientation in the embeddings, we selected the final model (EmbeddingGemma; \citet{embedding_gemma_2025}) based on (i) intra- and interparty cosine similarities, (ii) predictive performance of a logistic regression model with political affiliation as target variable, and (iii) K-means clustering quality (homogenity and completeness) with respect to party membership.

Dimensionality reduction has been used to study temporal ideological change and to recover latent political dimensions \citep{Rheault2020-mr}. % NOTE: I added that it was PCA because to me it was not really understandable - I hope it makes sense 
Exploratory PCA revealed that party affiliations have a minor effect on our embedding variance. 
To identify a subspace in which political differences become more salient, we use Partial Least Squares (PLS), which extracts directions maximally associated with party labels. To mitigate temporal bias, we excluded written speeches (leaving $n=5,433$) and % fit the PLS model on the remaining 5,433 observations, 
evaluate the model using temporally adapted leave-one-out cross-validation \citep{roberts_temporal_2017}.

The prevalence of established migration-related rhetoric is assessed using semantic search. We use 30 migration narratives identified in a recent report by the European Commission’s Joint Research Centre \citep[p.130]{seiger_navigating_2025}, organized into four broader ``supernarratives.'' Each narrative was represented by a short descriptive sentence and embedded. % using the model’s built-in ``retrieval-query'' prompt. 
Semantic proximity between narratives and migration speeches ($n = 9705$) is quantified using cosine similarity. Similarity scores are averaged across narratives within each supernarrative to capture high-level trends. To control for keyword-driven effects, we additionally constructed a control narrative at the presumed opposite end of the semantic spectrum (``We need to respect humanitarian principles in handling migration''). To validate that narrative similarity captures meaningful political differences, we correlate similarity scores with the CHES-ratings of party positions \citep{rovny_CHES_2024}. Temporal trends and party-bloc differences in narrative prevalence are analysed using linear mixed-effects models with random intercepts and slopes at the party-bloc level. Significance levels were Bonferroni-adjusted to the number of computed Pearson correlations ($p = 0.05/246$) and linear models ($p = 0.05/6$), respectively.
