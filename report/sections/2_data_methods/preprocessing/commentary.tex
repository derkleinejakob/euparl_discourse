
\subsubsection{Removing Commentary} 
% Shortened suggestion by Jakob 
The speeches often include bracketed comments that may contain markers of the original language, parliamentary incidents, or procedural notes. We removed these comments using rule-based methods. 

There are also substantial redundencies in the openning and closing sections of the speeches (greetings, etc.). These sections follow similar rhetorical structures but exhibit substantial lexical variation. To remove redundant formalities, we identified low-impact sentences using TF-IDF which scores the amount of information of a sentence (TODO, source). %[TODO: add source / publication where TF-IDF was first published]
Two independent raters annotated a sample of 100 low-scoring sentences for informational relevance. With these manual ratings, we fit a logistic regression model to estimate the threshold required to achieve 95\% accuracy for classifying the relevance of a sentence based on its TF/IDF score. For each speech, first and last sentences were removed if their TF-IDF score was below the computed threshold.

% We detect high amount of superfluous commentary in transliterated speeches:  markers of the original language, background incidents, and procedural notes. These markers might be source of unwanted bias, which we want to avoid. Fortunately they are predominantly located within parentheses and can be easily removed with rule-based methods. We also observe substantial redundency in the openning and closing sections of the speeches.
% These sections follow similar rhetorical structures but exhibit substantial lexical variation. To identify low-impact sentences we use TF-IDF algorithm to score the amount of information they contain.
% We construct separate corpora for opening and closing sentences, and an average TF-IDF score is computed for each sentence. Two independent raters annotated a sample of 100 low-scoring sentences for informational relevance. We then fit a logistic regression linking TFâ€“IDF score percentiles to these annotations and used the model to estimate the threshold required to achieve 95\% classification accuracy.
